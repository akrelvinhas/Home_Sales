# Home_Sales

Summary:
In this SparkSQL undertaking, the objective is to analyze a dataset on home sales, extracting crucial metrics through tasks such as creating temporary views, partitioning data, caching tables, and executing SparkSQL queries to gain valuable insights. Proficiency in SparkSQL, data manipulation, and optimization techniques is showcased through these project tasks.

Tasks:
1. Generate a Spark DataFrame from the home sales dataset.
2. Establish a temporary table for in-depth analysis.
3. Execute queries to determine average prices based on specific home attributes and view ratings.
4. Cache and verify temporary tables to enhance performance.
5. Examine runtime disparities between cached and uncached queries.
6. Implement partitioning and parquet data for more efficient storage.
7. Run queries on partitioned parquet data and compare execution times.
8. Ensure proper uncaching of temporary tables.

Conclusion:
This project underscores the effective utilization of SparkSQL for practical data analysis, demonstrating the ability to optimize performance through strategic caching and partitioning approaches.
